# S3

## General

- Storage de objetos
- Se puede almacenar virtualmente cualquier tipo de data
- El número de objetos y el volumen a almacenar son ilimitados
- Objetos pueden tener entre 0 B y 6 TB de tamaño
- De un solo PUT, el máximo a subir es de 5 GB
- Si el objeto a subir es de más de 100 MB, se recomienda usar Multipart Upload
- Clases de amacenamiento (configuradas a nivel objeto):
    - Standard: propósito general, data accedida frecuentemente
    - Standard-Infrequent Access: objetos de larga duración pero accedidos con menos frecuencia
    - One Zone-Infrequent Access: idem a IA, pero en una sola AZ
    - Intelligent-Tiering: automáticamente mueve data a la mejor clase
    - Glacier: archivado de data, tiempo de recuperación lento (minutos a horas)
    - Glacier Deep Archive: es más barato que Glacier, tiempo de recuperación más largo (12 horas)
- Amazon lo usa para sus operaciones
- Con versionamiento, cada versión de un objeto se cobra
- Es key-based
- Objetos se pueden taggear
- AWS se preocupa de escalar el servicio, aumento repentino de tráfico no afecta servicio

## Billing

- Solo se paga por lo que se usa
- Precio depende de región y clase
- No hay cargo de transferencia de datos en requests `COPY` dentro de una misma región
- No hay cargo de transferencia para requests entre un EC2 y S3 en misma región
- Free Tier incluye al mes 5 GB de almacenamiento, 20.000 GET requests, 2.000 PUT requests, 15 GB de transferencia entrante, 15 GB de transferencia saliente
- Uso es medido en `TimedStorage-ByteHrs`
- Se paga por obtención de objetos en S-IA, OZ-IA, G, GDA
- Acceder a objetos por AWS Management Console tiene los mismos costos que por otras vías
- Acceder a objetos por otras cuentas AWS tiene los mismos costos que por otras vías, a menos que se designe el bucket como “Requester Pays”

## Security

- S3 es seguro por defecto
- Soporte para autenticación de usuarios para controlar acceso a data
- Soporte para SSL
- Soporte para Server-Side Encryption para encriptación "at rest"
- Se puede configurar para que S3 encripte automáticamente objetos al almacenar si no vienen con información de encriptado
- 4 mecanismos para controlar acceso a recursos en S3 **(detallar)**:
	- IAM policies
	- Bucket policies
	- Access Control Lists
	- Query String Authentication: asignar URL a objeto válida solo por período de tiempo
- Se puede limitar acceso basado en HTTP referrer e IP
- Se pueden activar logs para todos los requests hacia un bucket
- 4 opciones para encriptar data:
	- SSE-S3: solución integrada, Amazon maneja las llaves
	- SS3-C: uno maneja las llaves, Amazon maneja (des)encriptación
	- SSE-KMS: Utiliza AWS Key Management Service para manejar las llaves. KMS entrega un audit trail
	- Librería como S3 Encryption Client: uno tiene control completo sobre las llaves y la (des)encriptación en client-side
- Un AWS VPC Endpoint es una entidad lógica que permite conectividad solo a S3. Se puede configurar un bucket para que solo se pueda acceder desde un Endpoint específico
- Amazon Macie sirve para automáticamente detectar, clasificar y proteger data sensible en un bucket con IA

## Durabilidad & Data Protection

- Durabilidad:
    - Todas las clases: 99.999999999% (11 9s)
    - RRS: 99.99%
    - Esto implica que si tienes 10 millones de objetos, se puede esperar perder uno cada 10 mil años
- Disponibilidad:
    - S: 99.99%
    - S-IA: 99.9%
    - OZ-IA: 99.5%
    - IT: 99.9%
    - G: -
    - GDA: -
    - RRS: 99.99%
- En todas las clases excepto OZ-IA, los objetos se almacenan en a lo menos 3 AZ redundantemente
- En OZ-IA, los objetos se almacenan en varios dispositivos pero en la misma AZ
- Utilización de checksums MD5 y Cyclic Redundancy Checks (CRC) para detectar corrupción de data. Cualquier corrupción detectada se arregla automáticamente con la data redundante
- Versionamiento: 
	- Permite guardar una versión para cada objeto almacenado
	- Esto incluye objetos eliminados
	- Por defecto, request GET obtendrá última versión
	- Se pueden obtener versiones antiguas especificándolas en el request
	- Solo el dueño de un bucket puede eliminar permanentemente un objeto
	- Soporte para Multi-Factor Authentication Delete, con el cual se requieren dos formas de autenticación para permanentemente borrar un objeto (credenciales de la cuenta y un código de 6 dígitos en un dispositivo físico con su número serial)
	- Cada versión de un objeto se cobra

## Intelligent-Tiering

- Clase de almacenamiento para objetos con patrones de acceso desconocidos o cambiantes
- Primero se almacenan los objetos la clase de acceso frecuente
- Objetos no accedidos en 30 días pasan a clase de acceso infrecuente
- Un objeto accedido en clase de acceso infrecuente es movido a clase de acceso frecuente
- No hay cargos por acceso
- Se puede poner objetos especificando `xx_xx`en el header `x-amz-storage` o con Lifecycle Policies
- Duración mínima de objetos de 30 días (objetos borrados antes serán cobrados con prorrateo)
- Objetos de menos de 128 KB no son sujetos a *auto-tiering*

## Standard-Infrequent Access

- Data accedida menos frecuentemente pero que requiere rápido acceso
- Baja tarifa por almacenamiento de GB y acceso de GB
- Ideal para backups y almacenamiento de largo plazo
- Se puede poner objetos especificando `STANDARD_IA`en el header `x-amz-storage` o con Lifecycle Policies
- Duración mínima de objetos de 30 días. Data eliminada antes será cobrada por 30 días
- Tamaño mínimo por objeto de 128 KB (objetos más livianos serán cobrados como si pesaran 128 KB)

## One Zone-Infrequent Access

- Usada para copias de backups y data recreable fácilmente
- Data reside en solo una AZ
- En caso de destrucción de la AZ donde reside, se perderá toda la data
- Almacenamiento 20% más barato que S-IA
- Otros precios son iguales a S-IA
- Duración mínima de objetos de 30 días. Data eliminada antes será cobrada por 30 días
- Tamaño mínimo por objeto de 128 KB (objetos más livianos serán cobrados como si pesaran 128 KB)
- La zona a utilizar es elegida por AWS según capacidad disponible, no por el usuario

## Glacier

- Antes llamado Amazon Glacier, ahora Amazon S3 Glacier
- Usada para archivado y backups
- Precios de almacenamiento extremadamente bajos
- 3 opciones para acceder a data:
	- Expedited: listo en 1-5 minutos (excepto para archivos de 250+ MB)
	- Standard: listo en 3-5 horas
	- Bulk: listo en 5-12 horas
- S3 Restore Speed Upgrade:
	- Para mover una restauración en progreso a una clase más rapida en caso de ser necesario
	- Se paga cada request y el costo de restauración por GB de la clase más rápida
- Al acceder data, automáticamente se crea una copia temporal en las clases RRS o S-IA, dejando la data original intacta en Glacier
- Se puede configurar cunatos días dura la copia
- Se puede configurar notificaciones cuando se complete una restauración, via SQS, SNS o Lambda
- Mínimo de almacenamiento de 90 días
- Objetos eliminados antes de 90 días serán prorrateados
- Eliminar data después de 90 días es gratis (si se elimina al día 30, se cobrará el fee de eliminado temprano por 60 días)
- Se cobra el total de la data de cada objeto más 32 KB de data de Glacier más 8 KB de data de la clase S
- Con Free Tier se pueden obtener 10 GB mensuales gratis

## Reduced Redundancy Storage

- Permite almacenar data no crítica y recreable en un menor nivel de redundancia
- Alta disponibilidad
- Replicado en varias AZ, pero no tiene la redundancia de otras clases

## Query in Place

- Correr queries sobre la data sin moverla a una plataforma de analytics, utilizando S3 como un data lake
- 3 opciones para consultar:
	- S3 Select: consultas SQL, para objetos en formato CSV, JSON o Apache Parquet, incluso si están comprimidos o encriptados (SSE)
	- Amazon Athena: serverless, consultas SQL, para objetos en formato CSV, JSON, ORC, Apache Parque, Avro. Puede manejar análisis complejo, `JOIN`s, arreglos
	- Amazon Redshift Spectrum: funcionalidad de Redshift, permite correr queries SQL contra exabytes de data no estructurada sin necesidad de usar ETLs. Escala automáticamente. Se pueden poner cuantos clustes de Redshift se necesiten

	
## Event Notification

- Notificaciones que pueden ser enviadas en respuestsa a acciones en S3 como `PUT`s, `POST`s, `COPY`s o `DELETE`s
- Pueden ser enviadas a través de SNS, SQS o Lambda
- Ejemplos: codificar media cuando sea subida, procesar data cuando esté disponible, sincronizar S3 con otro almacenamiento
- Pueden ser configuradas en base a sufijos o prefijos de objetos
- No tiene costo adicional (solo se paga el uso de SNS, SQS o Lambda)
- Formato XML

## Transfer Acceleration

- Permite subir objetos en forma rápida y segura
- Utiliza CloudFront y Edge Locations
- Se activa por bucket
- Para utilizarlo se deben enviar los requests `PUT` y `GET` al dominio de endpoint `s3-accelerate` (`.s3-accelerate.amazonaws.com`)
- Maximiza utilización de ancho de banda, minimiza distancia
- Aceleración depende de distancia entre fuente y destino, ancho de banda, y pérdida de paquetes
- Se verá más aceleración cuando la fuente está más lejos del destino y cuando el objeto es más grande
- Uso recomendado cuando se suben objetos a un bucket centralizado desde todo el mundo
- Usa la misma seguridad que las transferencias normales
- AWS calcula si Transfer Acceleration de verdad servirá, si no, no cobra extra
- Se puede usar con multipart uploads
- Para decidir entre Cloudfront y TA: usar TA si se requiere más flujo; la data es mayor a 1 GB
- Si va a deorar más de una semana en subirse en línea de 1 Gbps, usar TA
- No recomendado con Direct Connect si se tiene buena conexión
- Se puede configurar para complementar Storage Gateway
- HIPAA compliant

## Storage Management

### Tags

- Pares key-value aplicados a objetos
- Pueden ser agregados, modificados o eliminados en cualquier momento de la vida del objeto
- Hasta 10 tags por objeto
- Facilitan administración de objetos
- Pueden ser usados para limitar acceso
- Pueden ser añadidos/modificados/eliminados usando la Management Console, API, SDKs o CLI
- Pueden ser replicados con Cross-Region Replication (cuando ya está acitvada, se requieren nuevos permisos para que tags se repliquen)
- Precio basado en cantidad de tags y costo por request al añadirlos

### Storage Class Analysis

- Permite analizar los patrones de acceso a los objetos
- Mueve objetos a clase adecuada
- Se puede configurar para que monitoree buckets, prefijos o tags
- Se configura en la Management Console o con la S3 PUT Bucket Analytics API
- Costo de $0.10 por cada millón de objetos monitoreados por mes
- Se actualiza diariamente
- Se puede exportar el análisis a un bucket

### S3 Inventory

- Reporte agendado
- Entrega lista de objetos y su metadata en formato CSV, ORC o Parquet
- Se configura en Management Console o con PUT Bucket Inventory API
- Puede ser diario o semanal
- Puede ser configurado para obtener solo prefijos
- Se puede almacenar el reporte en un bucket
- Se puede configurar la metadata específica a reportar:
	- Nombre
	- Tamaño
	- Fecha de modificación
	- Clase de almacenamiento
	- ID de versionamiento
	- Marcador de eliminación
	- Bandera de *noncurrent version*
	- Bandera de multipart upload
	- Estado de replicación
	- Estado de encriptación
- Reporte puede ser encriptado con SSE-S3 o SSE-KMS
- $0.0025 por millón de objetos listados

### Batch operations

- Permite automatizar la ejecución manejo y auditoría de requests específicos o funciones Lambda a través de objetos en S3
- Sirve para automatizar reemplazo de tags, actualizar ACLs, copiar objetos entre buckets, inicializar restores desde Glacier
- Se usa desde Management Console, CLI o SDK
- Se puede ver progreso programáticamente o en la consola de S3
- Se pueden recibir notificaciones cuando termine la operación
- Priorizables
- Cancelables

### S3 Object Lock

- Bloquea la eliminación de versiones de un objeto durante un período de retención
- Pueden importance desde sistemas write-once-read-many (`WORM`)
- Configurables a nivel de bucket y objeto
- No depende de la clase de almacenamiento ni de transiciones via Lifecycle Policies
- Se pueden aplicar al momento de subir con un request PUT, o a objetos existentes
- Cuando se bloquea el objeto, este no puede ser modificado ni eliminado
- 2 modos:
	- Governance: solo cuentas con permisos IAM específicos podrán remover protección `WORM`
	- Compliance: protección `WORM` no puede ser eliminada, por ningún usuario
- Legal Hold aplica retención a un objeto indefinidamente, hasta que sea explícitamente eliminado (cuenta requiere permiso `PutObjectLegalHold`)

### CloudWatch Metrics

- Resolución de 1 minuto
- Disponibles dentro de 15 minutos después de ser habilitadas
- Configurables por prefijo o tag
- Métricas de Storage habilitadas por defecto para todos los buckets, reportadas una vez al día
- Se pueden poner límites en cualquier métrica y activar alarma cuando se cruce
- Métricas de Storage son gratis
- Métricas de requests tienen precios acorde a métricas customizadas de CloudWatch

### Lifecycle Management

- Provee la habilidad de determinar el ciclo de vida de un objeto con una política predefinida, reduciendo el costo de almacenamiento
- Se puede mover un objeto automáticamente de S a S-IA, OZ-IA o G en base a la antiguedad del objeto
- Se pueden expirar objetos basados en la antiguedad del objeto
- Se puede expirar un multipart upload incompleto basado en su antiguedad
- Configurables en la Management Console, API, SDKs o CLI
- Configurable para prefijos o buckets
- Política no tiene costo
- Si hay un precio por transition request por objeto
- En cada regla se puede especificar:
	- Prefijo
	- Período de tiempo (fecha de creación o tiempo desde creación)
	- Clase a trasladar
	- Expiración
- Políticas son aplicadas a objetos nuevos y existentes
- Se puede configurar a nivel objeto si se especifica el `key name`

### Cross-Region Replication

- Automáticamente replica data entre regiones
- Configurable a nivel bucket, prefijo o objeto utilizando tags
- Utilizado para entregar latencia de acceso más baja en zonas geográficas diferentes
- Se configura especificando la región de destino en el bucket fuente
- Se puede utilizar la Management Console, API, CLI o SKD para habilitarlo
- Versionamiento debe estar habilitado en la fuente y el destino
- Puede ser utilizado con Lifecycle Policies, con reglas distintas en fuente y destino
- Se puede copiar directamente a Glacier en una región diferente
- Se pueden replicar objetos encriptados con KMS, entregando la llave en la configuración de replicado
- Objetos son transmitidos encriptados vía SSL
- Se puede utilizar CRR Ownership Overwrite para evitar que un objeto borrado en fuente sea borrado en destino
- Se paga por almacenamiento, `COPY` request y transferencia entre regiones
- El costo de `COPY`request y data transfer se basa en la región fuente
- El costo de almacenamiento se basa en la región destino
- Objetos subidos con multipart upload se replican usando el mismo número de partes y tamaño de las partes

### IPv6

- S3 soporta IPv6
- Se activa un *dual-stack* para acceso via IPve e IPv6
- Se puede devolver a IPv4 en cualquier momento
- No disponible para Website Hosting y acceso via BitTorrent
